{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import gluon, nd, autograd\n",
    "#from gluoncv import utils\n",
    "import time, os, math, argparse\n",
    "\n",
    "mx.npx.set_np()\n",
    "\n",
    "parser = argparse.ArgumentParser(description='MXNet Gluon GZoo training')\n",
    "parser.add_argument('--root', type=str, default=r'/home/foivos/Projects/dl_workshop_2020/',\n",
    "                    help='root directory that contains GalaxyZoo code and data')\n",
    "parser.add_argument('--batch-size', type=int, default=8,\n",
    "                    help='batch size for training and testing (default:32)')\n",
    "parser.add_argument('--crop-size', type=int, default=256, # this is not the best solution, but ...\n",
    "                    help='crop size of input image, for memory efficiency(default:256)')\n",
    "parser.add_argument('--epochs', type=int, default=600,\n",
    "                    help='number of epochs to train (default: 600)')\n",
    "parser.add_argument('--lr', type=float, default=0.001,\n",
    "                    help='learning rate (default: 0.001)')\n",
    "parser.add_argument('--cuda', action='store_true', default=True,\n",
    "                    help='Train on GPU with CUDA')\n",
    "parser.add_argument('--nfilters_init',type=int, default=32,\n",
    "                    help='XX nfilters_init, default::32')\n",
    "parser.add_argument('--model',type=str, default='FracTALResNet',\n",
    "                    help='Model base for feature extraction, default::FracTALResNet')\n",
    "parser.add_argument('--depth',type=int, default=3,\n",
    "                    help='XX depth, default::4')\n",
    "parser.add_argument('--widths',type=list, default=[2],\n",
    "                    help='XX widths, default::2')\n",
    "parser.add_argument('--nheads_start',type=int, default=32//8,\n",
    "                    help='XX nheads_start, default::{}'.format(32//8))\n",
    "parser.add_argument('--in_features',type=int, default=1024,\n",
    "                    help='XX in_features, default::{}'.format(1024))\n",
    "parser.add_argument('--causal',type=bool, default=True,\n",
    "                    help='Model predictions HEAD, causal vs standard, default:: causal=True')\n",
    "\n",
    "\n",
    "opt = parser.parse_args(\"\")\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(opt.root)\n",
    "\n",
    "# Data augmentation definitions \n",
    "from mxnet.gluon.data.vision import transforms\n",
    "\n",
    "# Model definitions \n",
    "from GalaxyZoo.mxnet.models.xxnets import *\n",
    "\n",
    "if opt.causal:\n",
    "    tname = r'causal'\n",
    "flname_write = r'Results/'+ opt.model + r'_' + tname +r'.txt'\n",
    "\n",
    "# ================== SAVING best model ==================================\n",
    "import datetime, os\n",
    "stamp = datetime.datetime.now().strftime('%Y-%m-%d-Time-%H:%M:%S_')\n",
    "flname_save_weights = r'Results/' + stamp + opt.model+ '_best_model.params'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building block model::FracTALResNet\n",
      "depth:= 0, nfilters: 32, nheads::4, widths::2\n",
      "depth:= 1, nfilters: 64, nheads::8, widths::2\n",
      "depth:= 2, nfilters: 128, nheads::16, widths::2\n"
     ]
    }
   ],
   "source": [
    "# ================== SAVING best model ==================================\n",
    "import datetime, os\n",
    "stamp = datetime.datetime.now().strftime('%Y-%m-%d-Time-%H:%M:%S_')\n",
    "flname_save_weights = r'Results/' + stamp + opt.model+ '_best_model.params'\n",
    "# =========================================================================\n",
    "\n",
    "# Decide on cuda: \n",
    "if opt.cuda and mx.util.get_gpu_count():\n",
    "    ctx = mx.gpu()\n",
    "else:\n",
    "    ctx = mx.cpu()\n",
    "\n",
    "# Define model\n",
    "net = xxnets(nfilters_init = opt.nfilters_init, depth=opt.depth, widths=opt.widths, nheads_start = opt.nheads_start, model_name = opt.model, causal = opt.causal, psp_depth=2)\n",
    "net.initialize(ctx=ctx)\n",
    "net.hybridize()  # ZoomZoom!! \n",
    "\n",
    "# Data augmentation definitions \n",
    "transform_train = transforms.Compose([\n",
    "    # Randomly crop an area, and then resize it to be 32x32\n",
    "    transforms.RandomResizedCrop(opt.crop_size,scale=(0.6,1.)),\n",
    "    # Randomly flip the image horizontally/vertically\n",
    "    transforms.RandomFlipLeftRight(),\n",
    "    transforms.RandomFlipTopBottom(),\n",
    "    # Randomly jitter the brightness, contrast and saturation of the image\n",
    "    transforms.RandomColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "    # Transpose the image from height*width*num_channels to num_channels*height*width\n",
    "    # and map values from [0, 255] to [0,1]\n",
    "    transforms.ToTensor(),\n",
    "    # Normalize the image with mean and standard deviation calculated across all images\n",
    "    transforms.Normalize([11.663384, 10.260227,  7.65015 ], [21.421959, 18.044296, 15.494861])\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(opt.crop_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([11.663384, 10.260227,  7.65015 ], [21.421959, 18.044296, 15.494861])\n",
    "])\n",
    "\n",
    "# Datasets/DataLoaders \n",
    "from GalaxyZoo.mxnet.src.GZooDataset import *\n",
    "dataset_train = GZooData(root=os.path.join(opt.root,'GalaxyZoo'), transform=transform_train)\n",
    "datagen_train = gluon.data.DataLoader(dataset_train,batch_size=opt.batch_size,shuffle=True)\n",
    "\n",
    "dataset_dev = GZooData(root=os.path.join(opt.root,'GalaxyZoo'), mode='dev',transform=transform_test)\n",
    "datagen_dev = gluon.data.DataLoader(dataset_dev,batch_size=opt.batch_size,shuffle=False,last_batch='rollover')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam parameters                                                                                  \n",
    "optimizer = 'Adam'\n",
    "lr = opt.lr\n",
    "# *********************************************************************************************    \n",
    "# Epochs in which we want to step                                                                  \n",
    "steps_epochs = [200,350]\n",
    "# assuming we keep partial batches, see `last_batch` parameter of DataLoader                       \n",
    "iterations_per_epoch = math.ceil(len(dataset_train) / opt.batch_size)\n",
    "# iterations just before starts of epochs (iterations are 1-indexed)                               \n",
    "steps_iterations = [s*iterations_per_epoch for s in steps_epochs]\n",
    "scheduler = mx.lr_scheduler.MultiFactorScheduler(base_lr=lr, step= steps_iterations, factor=0.1)\n",
    "# **********************************************************************************************   \n",
    "optimizer_params = {'learning_rate': lr,'lr_scheduler':scheduler}\n",
    "trainer = gluon.Trainer(net.collect_params(), optimizer, optimizer_params)\n",
    "\n",
    "\n",
    "\n",
    "train_metric = gluon.metric.MSE()\n",
    "loss_fn  = gluon.loss.L1Loss()\n",
    "\n",
    "# development metric: \n",
    "def test(tctx, tnet, tdatagen_dev):\n",
    "    metric = gluon.metric.MSE()\n",
    "    print (\"started testing ...\")\n",
    "    for idx, data in enumerate(tdatagen_dev):\n",
    "        print(\"\\rRunning:: {}/{}\".format(idx+1,len(tdatagen_dev)),end='',flush=True)\n",
    "        #data = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0)\n",
    "        imgs, labels = data\n",
    "        imgs = imgs.as_in_context(tctx)\n",
    "        # outputs = [net(X) for X in data]\n",
    "        #outputs = nd.concatenate(outputs,axis=0)\n",
    "        with mx.autograd.predict_mode():\n",
    "            preds = tnet(imgs)\n",
    "        metric.update(preds=preds, labels=labels)\n",
    "        mx.npx.waitall() # necessary to avoid memory flooding \n",
    "    return metric.get()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started testing ...\n",
      "Running:: 769/769"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('mse', 0.18329831957817078)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(ctx,net,datagen_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6fecebd0febc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
