{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Predicting swell\n",
    "\n",
    "The docking jetty at Barrow Island\n",
    "\n",
    "![barrow](images/barrow.png)\n",
    "\n",
    "The waters around Barrow\n",
    "\n",
    "![chart](images/barrow-chart.png)\n",
    "\n",
    "\n",
    "The buoy location\n",
    "\n",
    "![buoy](images/buoy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data\n",
    "* Wave parameters\n",
    "    * Specific Wave Height\n",
    "    * Period peak wave\n",
    "    * Direction\n",
    "\n",
    "* Spectra 2d Frequency vs Direction\n",
    "\n",
    "![Spectra](images/2020-08-18Spectra.png)\n",
    "\n",
    "![HS](images/2020-08-18HS.png)\n",
    "\n",
    "From the spectra many parameters can be derived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def getMetricsNODC(theta, freq, E, u10=None, depth=999.0, nan=999.0, fh=None):\n",
    "    \"\"\"\n",
    "    Calculate standard mean wave parameters from directional\n",
    "    spectral density following Rogers & Wang (2007). The\n",
    "    routine uses WAVEWATCH III(R) spectral output.\n",
    "\n",
    "    Reference:\n",
    "       Tolman H (2009)  User manual and system documentation\n",
    "           of WAVEWATCH III(R) version 3.14. Tech Note 276, 220p.\n",
    "       Kuik AJ, GP van Vledder & L Holthuijsen (1988)\n",
    "           JPO, 18(7), 1020-1034\n",
    "\n",
    "    Input:\n",
    "      theta - directions      (in radians, _constants.deg2rad*(90.-nc.variables['direction']))\n",
    "      freq  - frequencies     (in Hz)\n",
    "      E     - directional wave spectra (in m2/rad-Hz)\n",
    "      u10   - wind speed      (in m/sec)\n",
    "      depth - depth           (in m)\n",
    "      nan   - value used for nan's (not a number)\n",
    "      fh    - cut-off frequency for the tail (in Hz)\n",
    "      basic - only calculate a subset of parameters\n",
    "    Output:\n",
    "      mPar   - mean parameters as type of python dictionary:\n",
    "               mPar['FP']    peak frequency           --+\n",
    "               mPar['FP1']   peak freq. (Young 1999)    |\n",
    "               mPar['DP']    peak wave period           |\n",
    "               mPar['DP1']   peak wave period w/ FP1    |\n",
    "               mPar['DPD']   peak wave direction        |\n",
    "               mPar['SWH']   significant wave height    |\n",
    "               mPar['MWD']   mean wave direction        |> integral\n",
    "               mPar['T01']   average period             |\n",
    "               mPar['T02']   zero-crossing period       |\n",
    "               mPar['TE']    energy period              |\n",
    "               mPar['CGE']   wave energy flux           |\n",
    "               mPar['BT']    breaking probability     --+\n",
    "               mPar['SPRD']  mean directional spread               --+\n",
    "               mPar['PSPR']  directional spread at FP                |\n",
    "               mPar['PSP2']  directional spread at 2FP               |\n",
    "               mPar['FSPR']  directional spread as func. of freq.    |\n",
    "               mPar['AFP']   directional narrowness at FP            |> spectral\n",
    "               mPar['A2FP']  direction narrowness at 2FP             |\n",
    "               mPar['ALPHA'] equilibrium interval level (alpha)      |\n",
    "               mPar['GAMMA'] spectral peakedness (gamma)             |\n",
    "               mPar['NU']    spectral width (Longuet-Higgins 1975) --+\n",
    "               mPar['WND']   wind speed               --+\n",
    "                                                        |> other\n",
    "                                                      --+\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-236d8f9339b5>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  File \u001B[0;32m\"<ipython-input-2-236d8f9339b5>\"\u001B[0;36m, line \u001B[0;32m1\u001B[0m\n\u001B[0;31m    1. Data preparation\u001B[0m\n\u001B[0m       ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Data preparation\n",
    "\n",
    "All the input files are in NetCDF.\n",
    "\n",
    "Under the hood NetCDF uses HDF5, BUT (a big but) you should not read it from HDF5 as:\n",
    "* Scaling is applied using metadata\n",
    "* The metadata is stored in other tables - not HDF5 attributes\n",
    "\n",
    "So I used xarray which opens then file and presents a dictionary back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_prediction_data(netcdf_filename, **kwargs):\n",
    "    tag_list = [\"times\"]\n",
    "    for label in kwargs[\"wave_parameters\"]:\n",
    "        tag_list.append(f\"{label}\")\n",
    "\n",
    "    data = xr.open_dataset(netcdf_filename)\n",
    "    return {tag: np.copy(data[tag]) for tag in tag_list}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Input data\n",
    "\n",
    "Each hindcast is for 7 days, with a forecast exevy hour, after 3 days the accuracy of the forecast is poor as can be seen below\n",
    "\n",
    "![day1](images/day1.png)\n",
    "\n",
    "![day2](images/day2.png)\n",
    "\n",
    "\n",
    "So we use a sliding window to get N\n",
    "\n",
    "Input data:\n",
    "* 1D spectra in frequency\n",
    "* 1D spectra in direction\n",
    "* Wind speed and direction\n",
    "* Tides\n",
    "* Time of day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Models\n",
    "\n",
    "To be sure of a good answer I train 4 different models and then combined the results using an ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.layers import (\n",
    "    Activation,\n",
    "    Layer,\n",
    "    GRU,\n",
    "    Dense,\n",
    "    Bidirectional,\n",
    "    concatenate,\n",
    "    Conv1D,\n",
    "    Flatten,\n",
    "    BatchNormalization,\n",
    "    Add,\n",
    "    MaxPooling1D,\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def cnn_residual_block(inputs_data: Layer, filters: int, kernel_size: int) -> Layer:\n",
    "    x = BatchNormalization()(inputs_data)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv1D(\n",
    "        filters=filters, kernel_size=kernel_size, use_bias=False, padding=\"same\"\n",
    "    )(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv1D(filters=filters, kernel_size=kernel_size, use_bias=True, padding=\"same\")(\n",
    "        x\n",
    "    )\n",
    "    return Add()([x, inputs_data])\n",
    "\n",
    "\n",
    "def dense_block(input_data: Layer, units: int, name: str = None) -> Layer:\n",
    "    x = Dense(units, use_bias=False, name=name)(input_data)\n",
    "    x = BatchNormalization()(x)\n",
    "    return Activation(\"tanh\", name=f\"activation_{name}\" if name is not None else None)(\n",
    "        x\n",
    "    )\n",
    "\n",
    "\n",
    "def cnn1d_block(inputs_data: Layer, filters: int, kernel_size: int) -> Layer:\n",
    "    x = Conv1D(\n",
    "        filters=filters, kernel_size=kernel_size, use_bias=False, padding=\"causal\"\n",
    "    )(inputs_data)\n",
    "    x = BatchNormalization()(x)\n",
    "    return Activation(\"relu\")(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## GRU\n",
    "\n",
    "The gated recurrent neural network.\n",
    "\n",
    "LSTM (Long Short Term Memory): LSTM has three gates (input, output and forget gate)\n",
    "\n",
    "GRU (Gated Recurring Units): GRU has two gates (reset and update gate).\n",
    "\n",
    "GRU couples forget as well as input gates.\n",
    "GRU use less training parameters and therefore use less memory, execute faster and train faster than LSTM's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_model_gru(\n",
    "    window_size: int, features: int, other_features: int, output_slots: int\n",
    ") -> Model:\n",
    "    LOGGER.info(\"Get model GRU\")\n",
    "    # define model\n",
    "    inputs1 = Input(shape=(window_size, features))\n",
    "    x = Bidirectional(\n",
    "        GRU(\n",
    "            128,\n",
    "            input_shape=(window_size, features),\n",
    "            return_sequences=True,\n",
    "        )\n",
    "    )(inputs1)\n",
    "    x = GRU(\n",
    "        256,\n",
    "        input_shape=(window_size, features),\n",
    "        return_sequences=True,\n",
    "    )(x)\n",
    "    x = GRU(\n",
    "        512,\n",
    "        input_shape=(window_size, features),\n",
    "        return_sequences=False,\n",
    "    )(x)\n",
    "    flat1 = Flatten()(x)\n",
    "\n",
    "    x = dense_block(flat1, 1024)\n",
    "    x = dense_block(x, 1024)\n",
    "    x = dense_block(x, 512)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    inputs2 = Input(shape=(other_features,))\n",
    "    flat2 = Dense(72, activation=\"relu\")(inputs2)\n",
    "    merged = concatenate([x, flat2], name=\"merged\")\n",
    "    x = dense_block(merged, 512)\n",
    "\n",
    "    outputs = Dense(output_slots, activation=\"tanh\", name=\"final_output\")(x)\n",
    "\n",
    "    model = Model(inputs=[inputs1, inputs2], outputs=outputs, name=\"gru\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## CNN1D\n",
    "\n",
    "A multi-headed CNN.\n",
    "This uses three different kernel sizes in parallel to extract, small, medium and large features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_model_cnn1d(\n",
    "    window_size: int, features: int, other_features: int, output_slots: int\n",
    ") -> Model:\n",
    "    LOGGER.info(\"Get model CNN1d\")\n",
    "    # define model\n",
    "    inputs1 = Input(shape=(window_size, features))\n",
    "\n",
    "    # Head 1\n",
    "    x = cnn1d_block(inputs1, 32, 3)\n",
    "    x = cnn1d_block(x, 32, 3)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "    x = cnn1d_block(x, 64, 3)\n",
    "    x = cnn1d_block(x, 128, 3)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    flat1 = Flatten()(x)\n",
    "\n",
    "    # Head 2\n",
    "    x = cnn1d_block(inputs1, 32, 5)\n",
    "    x = cnn1d_block(x, 32, 5)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "    x = cnn1d_block(x, 64, 5)\n",
    "    x = cnn1d_block(x, 128, 5)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    flat2 = Flatten()(x)\n",
    "\n",
    "    # head 3\n",
    "    x = cnn1d_block(inputs1, 32, 9)\n",
    "    x = cnn1d_block(x, 32, 9)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "    x = cnn1d_block(x, 64, 9)\n",
    "    x = cnn1d_block(x, 128, 9)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    flat3 = Flatten()(x)\n",
    "\n",
    "    merged = concatenate([flat1, flat2, flat3], name=\"merged1\")\n",
    "\n",
    "    x = dense_block(merged, 4096)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = dense_block(x, 1024)\n",
    "    x = dense_block(x, 512)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    inputs2 = Input(shape=(other_features,))\n",
    "    flat4 = Dense(72, activation=\"relu\")(inputs2)\n",
    "    merged = concatenate([x, flat4], name=\"merged2\")\n",
    "    x = dense_block(merged, 512)\n",
    "\n",
    "    outputs = Dense(output_slots, activation=\"tanh\", name=\"final_output\")(x)\n",
    "\n",
    "        model = Model(\n",
    "        inputs=[inputs1, inputs2],\n",
    "        outputs=outputs,\n",
    "        name=\"cnn1d\",\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_model_resnet1d(\n",
    "    window_size: int, features: int, other_features: int, output_slots: int\n",
    ") -> Model:\n",
    "    LOGGER.info(\"Get model resnet\")\n",
    "    # define model\n",
    "    inputs1 = Input(shape=(window_size, features))\n",
    "    kernel_size = 6\n",
    "    x = Conv1D(filters=128, kernel_size=kernel_size, padding=\"causal\")(inputs1)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # Block 1\n",
    "    x = cnn_residual_block(x, 128, kernel_size)\n",
    "\n",
    "    # 1/2 the size\n",
    "    x = Conv1D(\n",
    "        filters=256, kernel_size=kernel_size, strides=2, use_bias=True, padding=\"causal\"\n",
    "    )(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = cnn_residual_block(x, 256, kernel_size)\n",
    "\n",
    "    # 1/2 the size\n",
    "    x = Conv1D(\n",
    "        filters=512, kernel_size=kernel_size, strides=2, use_bias=True, padding=\"causal\"\n",
    "    )(x)\n",
    "    flat1 = Flatten()(x)\n",
    "\n",
    "    x = dense_block(flat1, 8192)\n",
    "    x = dense_block(x, 2048)\n",
    "    x = dense_block(x, 512)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    inputs2 = Input(shape=(other_features,))\n",
    "    flat2 = Dense(72, activation=\"relu\")(inputs2)\n",
    "    x = concatenate([x, flat2], name=\"merged2\")\n",
    "    x = dense_block(x, 512)\n",
    "\n",
    "    outputs = Dense(output_slots, activation=\"tanh\", name=\"final_output\")(x)\n",
    "\n",
    "    model = Model(\n",
    "        inputs=[inputs1, inputs2],\n",
    "        outputs=outputs,\n",
    "        name=\"ResNet\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_model_dense(\n",
    "    window_size: int, features: int, other_features: int, output_slots: int\n",
    ") -> Model:\n",
    "    LOGGER.info(\"Get model Dense\")\n",
    "    # define model\n",
    "    inputs1 = Input(shape=(window_size, features))\n",
    "    x = Flatten()(inputs1)\n",
    "    x = dense_block(x, 8192)\n",
    "    x = dense_block(x, 4096)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = dense_block(x, 2048)\n",
    "    x = dense_block(x, 1024)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    # Other inputs\n",
    "    inputs2 = Input(shape=(other_features,))\n",
    "    flat2 = Dense(72, activation=\"relu\")(inputs2)\n",
    "    merged = concatenate([x, flat2], name=\"merged2\")\n",
    "    x = dense_block(merged, 512)\n",
    "\n",
    "    outputs = Dense(output_slots, activation=\"tanh\", name=\"final_output\")(x)\n",
    "\n",
    "    model = Model(inputs=[inputs1, inputs2], outputs=outputs, name=\"dense\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_ensemble_model(result_dictionary: Dict, dense_nodes: int) -> Model:\n",
    "    LOGGER.info(\"Get model Ensemble\")\n",
    "    head_inputs = []\n",
    "    merge_inputs = []\n",
    "    input_data = next(iter(result_dictionary.values()))\n",
    "    shapes = input_data.shape[1]\n",
    "\n",
    "    # define model starting with multiheaded input\n",
    "    for key in SUB_MODELS:\n",
    "        if key in result_dictionary:\n",
    "            inputs = Input(shape=(shapes,), name=f\"inputs-{key}\")\n",
    "            head_inputs.append(inputs)\n",
    "            x = dense_block(inputs, shapes)\n",
    "            x = dense_block(x, shapes)\n",
    "            merge_inputs.append(x)\n",
    "\n",
    "    # Merge\n",
    "    merged = concatenate(merge_inputs)\n",
    "    x = dense_block(merged, dense_nodes)\n",
    "    x = dense_block(x, dense_nodes)\n",
    "    x = dense_block(x, dense_nodes)\n",
    "\n",
    "    outputs = Dense(shapes, activation=\"tanh\", name=\"final_output\")(x)\n",
    "\n",
    "    model = Model(inputs=head_inputs, outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S3 options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class S3ModelCheckpoint(Callback):\n",
    "    \"\"\"Callback to checkpoint code to S3 if needed\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        s3_bucket: str,\n",
    "        filename: PosixS3Name,\n",
    "        pause: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if s3_bucket is not None:\n",
    "            self._s3_copy = S3Helper(s3_bucket)\n",
    "            self._filename = filename\n",
    "            self._last_copy = self._mtime = time()\n",
    "            self._pause = pause\n",
    "        else:\n",
    "            self._s3_copy = None\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self._s3_copy is not None and exists(self._filename.posix_name):\n",
    "            new_mtime = getmtime(self._filename.posix_name)\n",
    "\n",
    "            # The file has changed\n",
    "            if new_mtime <= self._mtime:\n",
    "                return\n",
    "\n",
    "            if time() >= self._last_copy + self._pause:\n",
    "                self._s3_copy.copy_to_s3(\n",
    "                    self._filename.posix_name, self._filename.s3_name\n",
    "                )\n",
    "\n",
    "                # Update the last copy time\n",
    "                self._last_copy = time()\n",
    "\n",
    "                # Update the file mtime\n",
    "                self._mtime = new_mtime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Running in AWS\n",
    "\n",
    "Running in AWS can get expensive\n",
    "\n",
    "```\n",
    "#!/bin/bash\n",
    "\n",
    "if [ -z \"$1\" ]; then\n",
    "    echo -e \"\\nPlease call '$0 <month>' to run this command\\n\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "# Put a kill switch in\n",
    "sudo shutdown -h 1080\n",
    "\n",
    "# Run the code\n",
    "cd /home/ubuntu/ML-Chevron-2020/src\n",
    "git pull\n",
    "\n",
    "pipenv run python3 main.py train-spectra --yaml-tag=96-48 --months=$1\n",
    "\n",
    "pipenv run python3 main.py ensemble-spectra --yaml-tag=ensemble_spectra --months=$1\n",
    "\n",
    "echo Training complete\n",
    "\n",
    "sudo shutdown -h now\n",
    "```\n",
    "\n",
    "# Running in BoM\n",
    "\n",
    "BoM runs on the NCI.\n",
    "So jobs are submitted as SLURM."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}