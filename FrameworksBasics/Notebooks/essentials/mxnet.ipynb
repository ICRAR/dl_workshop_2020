{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MXNET \n",
    "\n",
    "mix-net, combines (mixes) both worlds, imperative and declarative programming. The gluon api is extremely friendly to use, and production ready. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip3 install --no-cache-dir --pre mxnet -f https://dist.mxnet.io/python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx \n",
    "mx.npx.set_np()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources \n",
    "#### Tutorials\n",
    "    1. https://gluon.mxnet.io/index.html\n",
    "    2. http://d2l.ai/\n",
    "    3. https://mxnet.incubator.apache.org/versions/master/tutorials/index.html \n",
    "\n",
    "#### Awesome mxnet\n",
    "    1. https://github.com/chinakook/Awesome-MXNet\n",
    "\n",
    "#### Community (forum)\n",
    "    1. https://discuss.mxnet.io/\n",
    "#### API Reference\n",
    "    1. https://mxnet.incubator.apache.org/versions/master/api/python/docs/api/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Array creation routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [5., 6., 7.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mx.np.array(((1,2,3),(5,6,7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "x = mx.np.ones((2,3))\n",
    "print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 -1  0]\n",
      " [ 0  0 -1]]\n"
     ]
    }
   ],
   "source": [
    "y = mx.np.random.randint(low=-1,high=1,size=(2,3))\n",
    "#y = nd.random.uniform(-1,1,(2,3))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2. 2. 2.]\n",
      " [2. 2. 2.]]\n"
     ]
    }
   ],
   "source": [
    "x = mx.np.full((2,3), 2.0)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 3), 6, dtype('float32'), cpu(0))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, x.size, x.dtype, x.context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0., -2.,  0.],\n",
       "       [ 0.,  0., -2.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 1., 2.],\n",
       "       [2., 2., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x+y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.36787945, 1.        ],\n",
       "       [1.        , 1.        , 0.36787945]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mx.np.exp(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing/slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(-1, dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1,  0],\n",
       "       [ 0, -1]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:,1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 2 2]\n",
      " [0 2 2]]\n"
     ]
    }
   ],
   "source": [
    "y[:,1:3]=2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 2]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:1,:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting\n",
    "\n",
    "Operating between two arrays (tensors) of different dimensionality:\n",
    "1. Follows numpy semantics\n",
    "2. They must have same rank\n",
    "3. The dimension that has value 1 is repeated along that axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "x =  [[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "-----------------\n",
      "y =  [[0. 1. 2.]]\n",
      "-----------------\n",
      "y.shape=  (1, 3)\n",
      "-----------------\n",
      "x + y =  [[1. 2. 3.]\n",
      " [1. 2. 3.]\n",
      " [1. 2. 3.]]\n",
      "-----------------\n",
      "x * y =  [[0. 1. 2.]\n",
      " [0. 1. 2.]\n",
      " [0. 1. 2.]]\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "x = mx.np.ones(shape=(3,3))\n",
    "print (\"-----------------\")\n",
    "print('x = ', x)\n",
    "y = mx.np.array([[0,1,2]]) # shape 1,3\n",
    "print (\"-----------------\")\n",
    "print('y = ', y)\n",
    "print (\"-----------------\")\n",
    "print('y.shape= ',y.shape)\n",
    "print (\"-----------------\")\n",
    "print('x + y = ', x + y)\n",
    "print (\"-----------------\")\n",
    "print('x * y = ', x * y)\n",
    "print (\"-----------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make explicit the dimension you want to broadcast to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "x =  [[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "-----------------\n",
      "y =  [[0.]\n",
      " [1.]\n",
      " [2.]]\n",
      "-----------------\n",
      "y.shape=  (3, 1)\n",
      "-----------------\n",
      "x + y =  [[1. 1. 1.]\n",
      " [2. 2. 2.]\n",
      " [3. 3. 3.]]\n",
      "-----------------\n",
      "x * y =  [[0. 0. 0.]\n",
      " [1. 1. 1.]\n",
      " [2. 2. 2.]]\n"
     ]
    }
   ],
   "source": [
    "x = mx.np.ones(shape=(3,3))\n",
    "print (\"-----------------\")\n",
    "print('x = ', x)\n",
    "y = mx.np.array([[0],[1],[2]]) # shape 3,1\n",
    "print (\"-----------------\")\n",
    "print('y = ', y)\n",
    "print (\"-----------------\")\n",
    "print('y.shape= ',y.shape)\n",
    "print (\"-----------------\")\n",
    "print('x + y = ', x + y)\n",
    "print (\"-----------------\")\n",
    "print('x * y = ', x * y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back and forth to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "a = x.asnumpy()\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "x = mx.np.array(a)\n",
    "print (x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing context (device) - CPU/GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find out how many available gpus exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "# Print number of available GPUs\n",
    "print(mx.util.get_gpu_count())\n",
    "# This a list of available indices that correspond to gpu devices\n",
    "print(list(mx.test_utils.list_gpus()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "cpu(0)\n"
     ]
    }
   ],
   "source": [
    "#a = nd.ones((2,2),ctx=mx.gpu())\n",
    "a = mx.np.ones((2,2),ctx=mx.gpu(0)) # index can be different, if more than 1 GPUs available\n",
    "a = mx.np.ones((2,2)) # defalut device/context mx.cpu()\n",
    "print (a)\n",
    "print(a.context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "cpu(0)\n"
     ]
    }
   ],
   "source": [
    "# Alternative way to copy into different context, after creation\n",
    "a = a.as_in_context(mx.cpu())\n",
    "print(a)\n",
    "print(a.context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In order to perform operations between tensors (vectors), both of them must live in the same device (context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5488135  0.5928446  0.71518934]\n",
      " [0.84426576 0.60276335 0.8579456 ]\n",
      " [0.5448832  0.8472517  0.4236548 ]]\n",
      "[[0.74021935 0.9209938  0.03902049]\n",
      " [0.9689629  0.92514056 0.4463501 ]\n",
      " [0.6673192  0.10993068 0.4702186 ]] @gpu(0)\n"
     ]
    }
   ],
   "source": [
    "a = mx.np.random.rand(3,3,ctx=mx.cpu()) # lives on CPU\n",
    "print (a)\n",
    "b = mx.np.random.rand(3,3,ctx=mx.gpu()) # lives on GPU\n",
    "print (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.2890329 1.5138384 0.7542098]\n",
      " [1.8132286 1.5279039 1.3042958]\n",
      " [1.2122023 0.9571824 0.8938734]] @gpu(0)\n",
      "[[1.2890329 1.5138384 0.7542098]\n",
      " [1.8132286 1.5279039 1.3042958]\n",
      " [1.2122023 0.9571824 0.8938734]]\n"
     ]
    }
   ],
   "source": [
    "# Correct operation \n",
    "print (a.as_in_context(mx.gpu())+b) # copy a to G-pu, result lives on GPU\n",
    "print (a+b.as_in_context(mx.cpu())) # copy b to C-pu, result lives on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "MXNetError",
     "evalue": "Traceback (most recent call last):\n  File \"../src/imperative/./imperative_utils.h\", line 136\nMXNetError: Check failed: inputs[i]->ctx().dev_mask() == ctx.dev_mask() (2 vs. 1) : Operator _npi_add require all inputs live on the same context. But the first argument is on cpu(0) while the 2-th argument is on gpu(0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMXNetError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-8e9622aee311>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# to err is to learn:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/mxnet/numpy/multiarray.py\u001b[0m in \u001b[0;36m_wrap_mxnp_np_ufunc\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_np\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_as_mx_np_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrap_mxnp_np_ufunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/mxnet/numpy/multiarray.py\u001b[0m in \u001b[0;36m__add__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1002\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__add__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m         \u001b[0;34m\"\"\"x.__add__(y) <=> x + y\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwrap_mxnp_np_ufunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/mxnet/util.py\u001b[0m in \u001b[0;36m_wrap_np_binary_func\u001b[0;34m(x1, x2, out, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m                     \u001b[0;31m# otherwise raise TypeError with not understood error message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} {} not understood\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrap_np_binary_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/mxnet/numpy/multiarray.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(x1, x2, out, **kwargs)\u001b[0m\n\u001b[1;32m   3194\u001b[0m            [ 6.,  8., 10.]])\n\u001b[1;32m   3195\u001b[0m     \"\"\"\n\u001b[0;32m-> 3196\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_mx_nd_np\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/mxnet/util.py\u001b[0m in \u001b[0;36m_wrap_np_binary_func\u001b[0;34m(x1, x2, out, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m                     \u001b[0;31m# otherwise raise TypeError with not understood error message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} {} not understood\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrap_np_binary_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/mxnet/ndarray/numpy/_op.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(x1, x2, out, **kwargs)\u001b[0m\n\u001b[1;32m   1011\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_types\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_np\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_api_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/mxnet/_ffi/_ctypes/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 ctypes.byref(ret_val), ctypes.byref(ret_tcode)) != 0:\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mget_last_ffi_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMXNetError\u001b[0m: Traceback (most recent call last):\n  File \"../src/imperative/./imperative_utils.h\", line 136\nMXNetError: Check failed: inputs[i]->ctx().dev_mask() == ctx.dev_mask() (2 vs. 1) : Operator _npi_add require all inputs live on the same context. But the first argument is on cpu(0) while the 2-th argument is on gpu(0)"
     ]
    }
   ],
   "source": [
    "# to err is to learn:\n",
    "print (a+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some basic linear algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a as an array:=  [3.]\n",
      "this is a as a float:=  3.0\n"
     ]
    }
   ],
   "source": [
    "a = mx.np.array([3])\n",
    "print (\"This is a as an array:= \",a)\n",
    "a = a.item() # return to standard float variable\n",
    "print (\"this is a as a float:= \",a) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### matrix-vector product (not broadcasting!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=  [[0.6235637  0.6458941  0.3843817  0.4375872  0.2975346 ]\n",
      " [0.891773   0.05671298 0.96366274 0.2726563  0.3834415 ]]\n",
      "b=  [[0.47766513]\n",
      " [0.79172504]\n",
      " [0.8121687 ]\n",
      " [0.5288949 ]\n",
      " [0.47997716]]\n"
     ]
    }
   ],
   "source": [
    "a = mx.np.random.rand(2,5)\n",
    "print (\"a= \",a)\n",
    "b = mx.np.random.rand(5,1) # Compare with declaring explicitely \n",
    "print (\"b= \",b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result=  [[1.4956555]\n",
      " [1.5817764]]\n",
      "shape of output matrix:  (2, 1)\n"
     ]
    }
   ],
   "source": [
    "# tip: these exists also batch_dot, for dot per batch element\n",
    "result = mx.np.dot(a,b)\n",
    "print (\"result= \", result)\n",
    "print (\"shape of output matrix: \", result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with declaring matrix b only with its first dimension "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial b.shape=  (5, 1)\n",
      "new shape of b:  (5,)\n"
     ]
    }
   ],
   "source": [
    "print (\"initial b.shape= \", b.shape)\n",
    "b = mx.np.squeeze(b) # just like np.squeeze - removes the redundant dimension\n",
    "# alternative: b.squeeze()\n",
    "print (\"new shape of b: \", b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result=  [1.4956555 1.5817764]\n",
      "shape of output matrix:  (2,)\n"
     ]
    }
   ],
   "source": [
    "result = mx.np.dot(a,b)\n",
    "print (\"result= \", result)\n",
    "print (\"shape of output matrix: \", result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### matrix-matrix product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=  [[0.56804454 0.3927848  0.92559665 0.83607876 0.07103606]\n",
      " [0.33739617 0.08712929 0.6481719  0.0202184  0.36824155]\n",
      " [0.83261985 0.95715517 0.77815676 0.14035077 0.87001216]]\n",
      "b=  [[0.87008727 0.9786183 ]\n",
      " [0.47360805 0.7991586 ]\n",
      " [0.8009108  0.46147937]\n",
      " [0.5204775  0.7805292 ]\n",
      " [0.67887956 0.11827442]]\n"
     ]
    }
   ],
   "source": [
    "a = mx.np.random.rand(3,5)\n",
    "print (\"a= \",a)\n",
    "b = mx.np.random.rand(5,2) # Compare with declaring explicitely \n",
    "print (\"b= \",b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result=  [[1.9049797 1.9579254]\n",
      " [1.1144719 0.7582647]\n",
      " [2.4646852 2.1512873]]\n",
      "shape of output matrix:  (3, 2)\n"
     ]
    }
   ],
   "source": [
    "result = mx.np.dot(a,b)\n",
    "print (\"result= \", result)\n",
    "print (\"shape of output matrix: \", result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip**: A handy operation in mxnet is nd.reshape, to change the shape of a tensor/layer/Array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.shape before:=  (3, 5)\n",
      "a.shape after:=  (15,)\n"
     ]
    }
   ],
   "source": [
    "print (\"a.shape before:= \", a.shape)\n",
    "a = a.reshape(-1) # equivalent to np.flatten\n",
    "print (\"a.shape after:= \",a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic differentiation\n",
    "\n",
    "We train neural networks with (modified versions of) gradient descent. Therefore we need a mechanism that automatically evaluates derivatives for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = {x1=0, x2=1, x3=2, x4=3}, represented as a column vector\n",
    "x = mx.np.array([0.,1.,2.,3.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "print (x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x.grad stores the value of the derivatives of functions that take x as input, with respect to x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to explicitely declare we require gradient evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.attach_grad() # default grad_req='write': overwrites previous gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mxnet.numpy.ndarray"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print (x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y=f(x)=x^2 \\rightarrow \\frac{dy}{dx}=2x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record the forward graph  of the computation so as to backpropagate ( ~ chain rule) \n",
    "# for the evaluation of the derivatives\n",
    "with autograd.record(): # Record the graph that described the functional relationships \n",
    "    y = x**2 # This is element-wise power of 2\n",
    "# Do the actual derivative evaluation  \n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 2. 4. 6.] [0. 2. 4. 6.]\n"
     ]
    }
   ],
   "source": [
    "# This must be 2*x\n",
    "print (x.grad, 2*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A bit more complex\n",
    "with autograd.record():\n",
    "    z = x**2\n",
    "    y = z*z\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.   4.  32. 108.] [  0.   4.  32. 108.]\n"
     ]
    }
   ],
   "source": [
    "# This must be 4 * x^3\n",
    "print (x.grad, 4*x**3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attention: \n",
    "x.grad contains the gradients of the derivative f(x), for an abritrary function x, i.e. \n",
    "$\\frac{f(x)}{dx} == x.grad $. Make sure to note that $x.grad \\neq \\frac{dx}{dx} =1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip**: the operation detach() removes the current tensor from the computation graph, handy when we train simultaneously multiple networks (e.g. GANs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.detach()# Now this is a new object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print (x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MAYDAY**: In mxnet, by default, every subsequent call of f(x).backward() overwrites the previous gradients (todo: grad_req='write'). So we don't need to manually set the values of x.grad to zero after each computation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suggested reading: autograd, head gradients: \n",
    "http://d2l.ai/chapter_crashcourse/autograd.html#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
